import streamlit as st
import pandas as pd
import numpy as np
import joblib
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import RobustScaler
import os
from io import BytesIO

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Isolation Forest
@st.cache_resource
def load_model():
    return joblib.load("model/isolation_forest.pkl")

# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
def analyze_anomalies(df, model):
    feature_cols = ['V1', 'V2', 'V3', 'A1', 'A2', 'A3']
    df.columns = df.columns.str.strip()
    df[feature_cols] = df[feature_cols].apply(pd.to_numeric, errors='coerce')
    df = df.dropna(subset=feature_cols)

    X = df[feature_cols]
    scaler = RobustScaler()
    X_scaled = scaler.fit_transform(X)

    # Isolation Forest
    iso_scores = model.decision_function(X_scaled)
    iso_preds = model.predict(X_scaled)

    # LOF
    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.02)
    lof_preds = lof.fit_predict(X_scaled)

    df_result = df.copy()
    df_result['IForest'] = iso_preds
    df_result['LOF'] = lof_preds

    # ØªØµÙ†ÙŠÙ Ø§Ù„Ø­Ø§Ù„Ø§Øª
    def classify(row):
        if row['IForest'] == -1 and row['LOF'] == -1:
            return 'Ø£ÙˆÙ„ÙˆÙŠØ© 1 - ÙƒÙ„Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ†'
        elif row['IForest'] == -1 or row['LOF'] == -1:
            return 'Ø£ÙˆÙ„ÙˆÙŠØ© 2 - Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ø­Ø¯'
        else:
            return 'Ø³Ù„ÙŠÙ…'

    df_result['Ø§Ù„ØªØµÙ†ÙŠÙ'] = df_result.apply(classify, axis=1)
    return df_result

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.set_page_config(page_title="Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ ÙØ§Ù‚Ø¯ Ø§Ù„Ø·Ø§Ù‚Ø©", layout="wide")
st.title("âš¡ Ù†Ø¸Ø§Ù… Ø§ÙƒØªØ´Ø§Ù Ø­Ø§Ù„Ø§Øª Ø§Ù„ÙØ§Ù‚Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
st.markdown("ğŸ“ˆ **ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø£Ø­Ù…Ø§Ù„ (CSV Ø£Ùˆ Excel) Ù„ØªØ­Ù„ÙŠÙ„Ù‡ ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø§Ø°Ø©**")

uploaded_file = st.file_uploader("ğŸ“¤ Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", type=["csv", "xlsx"])

if uploaded_file:
    st.success("âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­.")

    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if uploaded_file.name.endswith('.csv'):
        df = pd.read_csv(uploaded_file, sep=';')
    else:
        df = pd.read_excel(uploaded_file)

    st.subheader("ğŸ“Š Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    st.dataframe(df.head())

    model = load_model()

    if st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„"):
        with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ†..."):
            results = analyze_anomalies(df, model)

        st.success("ğŸ‰ ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„.")
        st.subheader("ğŸ“Œ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„Ø©:")
        st.dataframe(results)

        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª Excel Ù…Ø¤Ù‚ØªØ©
        def convert_df_to_excel(df_data):
            output = BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                df_data.to_excel(writer, index=False, sheet_name='Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„')
            output.seek(0)
            return output

        download_df = results[results['Ø§Ù„ØªØµÙ†ÙŠÙ'] != 'Ø³Ù„ÙŠÙ…']

        st.markdown("### ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        col1, col2 = st.columns(2)

        with col1:
            st.download_button(
                "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Excel)",
                convert_df_to_excel(results),
                file_name="all_results.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

        with col2:
            st.download_button(
                "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø§Ø°Ø© ÙÙ‚Ø· (Excel)",
                convert_df_to_excel(download_df),
                file_name="anomalies_only.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

# Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø·ÙˆØ±
st.markdown("---")
st.markdown("""
ğŸ‘¨â€ğŸ’» **Ø§Ù„Ù…Ø·ÙˆØ±:** Ù…Ø´Ù‡ÙˆØ± Ø§Ù„Ø¹Ø¨Ø§Ø³  
ğŸ“ **Ø±Ù‚Ù… Ø§Ù„ØªÙˆØ§ØµÙ„:** 00966553339838  
ğŸ“… **Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«:** 07-08-2025
""")
